{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ab770ed628a729"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File names in the folder:\n",
      "result_with_parameters_0.csv\n",
      "result_with_parameters_1.csv\n",
      "result_with_parameters_2.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_file_names(folder_path):\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Filter out directories, leaving only files\n",
    "    file_names = [file for file in files if os.path.isfile(os.path.join(folder_path, file))]\n",
    "    return file_names\n",
    "\n",
    "folder_path = './marked_data'\n",
    "file_names = get_file_names(folder_path)\n",
    "print(\"File names in the folder:\")\n",
    "for file_name in file_names:\n",
    "    print(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:23:21.729773800Z",
     "start_time": "2024-02-24T16:23:21.724800700Z"
    }
   },
   "id": "65d44aae2e5aa652",
   "execution_count": 181
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        close    open    high     low  volume  past_EMA  current_EMA  \\\n0      270.22  270.22  270.61  270.20      70 -0.063712     0.436842   \n1      270.60  270.60  270.60  270.23      36  0.436842     0.852394   \n2      270.60  270.60  270.61  270.07     236  0.852394     1.223820   \n3      270.60  270.25  270.60  270.07      52  1.223820     1.555370   \n4      270.11  270.60  270.60  270.09     136  1.555370     1.892675   \n...       ...     ...     ...     ...     ...       ...          ...   \n21564  276.07  276.06  276.10  276.06     930 -0.077712    -0.074969   \n21565  276.06  276.07  276.19  276.06    2371 -0.074969    -0.071588   \n21566  276.10  276.13  276.14  276.06     204 -0.071588    -0.071903   \n21567  276.10  276.09  276.10  276.09       5 -0.071903    -0.072117   \n21568  276.00  276.09  276.10  275.92    4630 -0.072117    -0.063712   \n\n       current_RSI   past_RSI  past_MACD  current_MACD  current_OBV  \\\n0        13.189032  49.574189   0.023510      0.001368     9.200000   \n1        17.223395  13.189032   0.001368      0.011350     8.400000   \n2        17.223395  17.223395   0.011350      0.016666    12.533333   \n3        17.223395  17.223395   0.016666      0.018742     7.733333   \n4        16.221694  17.223395   0.018742     -0.012636     3.466667   \n...            ...        ...        ...           ...          ...   \n21564    51.333664  51.094821  -0.010906     -0.009423    48.133333   \n21565    51.081684  51.333664  -0.009423     -0.008656  -168.466667   \n21566    52.032965  51.081684  -0.008656     -0.005167  -183.466667   \n21567    52.032965  52.032965  -0.005167     -0.002696  -128.266667   \n21568    49.574189  52.032965  -0.002696     -0.007368  -420.000000   \n\n         upper_BB    lower_BB  %K_StochRSI       ATR  up_Aroon  low_Aroon  \n0      270.751797  269.990203    11.392405  1.383741      92.0       28.0  \n1      270.777576  269.989424    35.443038  1.382825      88.0       24.0  \n2      270.780016  270.043984    35.443038  1.393303      84.0       20.0  \n3      270.797415  270.042585    35.443038  1.402416      80.0       16.0  \n4      270.805300  270.001700     0.000000  1.409589      76.0       12.0  \n...           ...         ...          ...       ...       ...        ...  \n21564  276.205463  276.010537     1.754386  1.031477      48.0       12.0  \n21565  276.206069  276.007931     0.877193  1.038045      44.0        8.0  \n21566  276.206108  276.010892     4.424779  1.040842      40.0        4.0  \n21567  276.206026  276.013974     4.424779  1.038786      36.0        8.0  \n21568  276.212899  275.997101     0.000000  1.048200      32.0      100.0  \n\n[21569 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>volume</th>\n      <th>past_EMA</th>\n      <th>current_EMA</th>\n      <th>current_RSI</th>\n      <th>past_RSI</th>\n      <th>past_MACD</th>\n      <th>current_MACD</th>\n      <th>current_OBV</th>\n      <th>upper_BB</th>\n      <th>lower_BB</th>\n      <th>%K_StochRSI</th>\n      <th>ATR</th>\n      <th>up_Aroon</th>\n      <th>low_Aroon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>270.22</td>\n      <td>270.22</td>\n      <td>270.61</td>\n      <td>270.20</td>\n      <td>70</td>\n      <td>-0.063712</td>\n      <td>0.436842</td>\n      <td>13.189032</td>\n      <td>49.574189</td>\n      <td>0.023510</td>\n      <td>0.001368</td>\n      <td>9.200000</td>\n      <td>270.751797</td>\n      <td>269.990203</td>\n      <td>11.392405</td>\n      <td>1.383741</td>\n      <td>92.0</td>\n      <td>28.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>270.60</td>\n      <td>270.60</td>\n      <td>270.60</td>\n      <td>270.23</td>\n      <td>36</td>\n      <td>0.436842</td>\n      <td>0.852394</td>\n      <td>17.223395</td>\n      <td>13.189032</td>\n      <td>0.001368</td>\n      <td>0.011350</td>\n      <td>8.400000</td>\n      <td>270.777576</td>\n      <td>269.989424</td>\n      <td>35.443038</td>\n      <td>1.382825</td>\n      <td>88.0</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>270.60</td>\n      <td>270.60</td>\n      <td>270.61</td>\n      <td>270.07</td>\n      <td>236</td>\n      <td>0.852394</td>\n      <td>1.223820</td>\n      <td>17.223395</td>\n      <td>17.223395</td>\n      <td>0.011350</td>\n      <td>0.016666</td>\n      <td>12.533333</td>\n      <td>270.780016</td>\n      <td>270.043984</td>\n      <td>35.443038</td>\n      <td>1.393303</td>\n      <td>84.0</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>270.60</td>\n      <td>270.25</td>\n      <td>270.60</td>\n      <td>270.07</td>\n      <td>52</td>\n      <td>1.223820</td>\n      <td>1.555370</td>\n      <td>17.223395</td>\n      <td>17.223395</td>\n      <td>0.016666</td>\n      <td>0.018742</td>\n      <td>7.733333</td>\n      <td>270.797415</td>\n      <td>270.042585</td>\n      <td>35.443038</td>\n      <td>1.402416</td>\n      <td>80.0</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>270.11</td>\n      <td>270.60</td>\n      <td>270.60</td>\n      <td>270.09</td>\n      <td>136</td>\n      <td>1.555370</td>\n      <td>1.892675</td>\n      <td>16.221694</td>\n      <td>17.223395</td>\n      <td>0.018742</td>\n      <td>-0.012636</td>\n      <td>3.466667</td>\n      <td>270.805300</td>\n      <td>270.001700</td>\n      <td>0.000000</td>\n      <td>1.409589</td>\n      <td>76.0</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21564</th>\n      <td>276.07</td>\n      <td>276.06</td>\n      <td>276.10</td>\n      <td>276.06</td>\n      <td>930</td>\n      <td>-0.077712</td>\n      <td>-0.074969</td>\n      <td>51.333664</td>\n      <td>51.094821</td>\n      <td>-0.010906</td>\n      <td>-0.009423</td>\n      <td>48.133333</td>\n      <td>276.205463</td>\n      <td>276.010537</td>\n      <td>1.754386</td>\n      <td>1.031477</td>\n      <td>48.0</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>21565</th>\n      <td>276.06</td>\n      <td>276.07</td>\n      <td>276.19</td>\n      <td>276.06</td>\n      <td>2371</td>\n      <td>-0.074969</td>\n      <td>-0.071588</td>\n      <td>51.081684</td>\n      <td>51.333664</td>\n      <td>-0.009423</td>\n      <td>-0.008656</td>\n      <td>-168.466667</td>\n      <td>276.206069</td>\n      <td>276.007931</td>\n      <td>0.877193</td>\n      <td>1.038045</td>\n      <td>44.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>21566</th>\n      <td>276.10</td>\n      <td>276.13</td>\n      <td>276.14</td>\n      <td>276.06</td>\n      <td>204</td>\n      <td>-0.071588</td>\n      <td>-0.071903</td>\n      <td>52.032965</td>\n      <td>51.081684</td>\n      <td>-0.008656</td>\n      <td>-0.005167</td>\n      <td>-183.466667</td>\n      <td>276.206108</td>\n      <td>276.010892</td>\n      <td>4.424779</td>\n      <td>1.040842</td>\n      <td>40.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>21567</th>\n      <td>276.10</td>\n      <td>276.09</td>\n      <td>276.10</td>\n      <td>276.09</td>\n      <td>5</td>\n      <td>-0.071903</td>\n      <td>-0.072117</td>\n      <td>52.032965</td>\n      <td>52.032965</td>\n      <td>-0.005167</td>\n      <td>-0.002696</td>\n      <td>-128.266667</td>\n      <td>276.206026</td>\n      <td>276.013974</td>\n      <td>4.424779</td>\n      <td>1.038786</td>\n      <td>36.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>21568</th>\n      <td>276.00</td>\n      <td>276.09</td>\n      <td>276.10</td>\n      <td>275.92</td>\n      <td>4630</td>\n      <td>-0.072117</td>\n      <td>-0.063712</td>\n      <td>49.574189</td>\n      <td>52.032965</td>\n      <td>-0.002696</td>\n      <td>-0.007368</td>\n      <td>-420.000000</td>\n      <td>276.212899</td>\n      <td>275.997101</td>\n      <td>0.000000</td>\n      <td>1.048200</td>\n      <td>32.0</td>\n      <td>100.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>21569 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = list()\n",
    "for i, file_name in enumerate(file_names):\n",
    "    temp = pd.read_csv(f'./marked_data/{file_name}')\n",
    "    temp = temp.drop([\"index\", \"past_OBV\", \"upper_ST\", \"lower_ST\"], axis=1)\n",
    "    data_for_analysis = temp\n",
    "    y, X = temp[\"result\"], temp.drop([\"result\"], axis=1)\n",
    "    data.append([y, X])\n",
    "    \n",
    "data[2][1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:23:23.813889800Z",
     "start_time": "2024-02-24T16:23:23.650113100Z"
    }
   },
   "id": "90ea2fb132004e92",
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# get data\n",
    "divided_data = list()\n",
    "for data_train in data:\n",
    "    divided_data.append(train_test_split(data_train[1], data_train[0], test_size=0.20, random_state = 2020, stratify=data_train[0]))\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 2020, stratify=y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:23:25.923593400Z",
     "start_time": "2024-02-24T16:23:25.891947500Z"
    }
   },
   "id": "908bbe75c64ee7d",
   "execution_count": 183
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scale Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8a98b4090b1530f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.71856253,  0.71737162,  0.71565183, ..., -0.66004104,\n         0.96219617, -1.34887654],\n       [ 0.55370204,  0.55343777,  0.54955531, ..., -0.76041134,\n         0.49027163, -1.34887654],\n       [ 0.33976458,  0.33303253,  0.33439569, ..., -0.12614371,\n        -1.04348313,  0.90823864],\n       ...,\n       [-1.77603152, -1.7693378 , -1.81371463, ..., -0.74206906,\n         0.71508586, -1.13595917],\n       [ 0.96269679,  0.94874084,  0.98251408, ..., -0.24320639,\n        -0.48701134,  0.79984405],\n       [ 0.40265759,  0.4365401 ,  0.41914613, ..., -0.39699525,\n         0.23424698, -0.53102067]])"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "for i, data_train in enumerate(divided_data):\n",
    "    divided_data[i][0] = ss.fit_transform(data_train[0])\n",
    "    divided_data[i][1] = ss.fit_transform(data_train[1])\n",
    "    \n",
    "X_train_list, X_test_list, y_train_list, y_test_list = [], [], [], []\n",
    "\n",
    "for i, data_train in enumerate(divided_data):\n",
    "    X_train_list.append(data_train[0])\n",
    "    X_test_list.append(data_train[1])\n",
    "    y_train_list.append(data_train[2])\n",
    "    y_test_list.append(data_train[3])\n",
    "\n",
    "X_train_scaled = np.concatenate(X_train_list, axis=0)\n",
    "X_test_scaled = np.concatenate(X_test_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "y_test = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "X_train_scaled\n",
    "# X_train_scaled = ss.fit_transform(X_train)\n",
    "# X_test_scaled = ss.transform(X_test)\n",
    "# y_train = np.array(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:23:28.469760100Z",
     "start_time": "2024-02-24T16:23:28.436708500Z"
    }
   },
   "id": "f5d4a0e7df5e67ea",
   "execution_count": 184
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Over Sampling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf27cb7fe95ab72"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.71856253,  0.71737162,  0.71565183, ..., -0.66004104,\n         0.96219617, -1.34887654],\n       [ 0.55370204,  0.55343777,  0.54955531, ..., -0.76041134,\n         0.49027163, -1.34887654],\n       [ 0.33976458,  0.33303253,  0.33439569, ..., -0.12614371,\n        -1.04348313,  0.90823864],\n       ...,\n       [-1.54643631, -1.5492015 , -1.39462384, ...,  1.39998775,\n        -1.01389715,  0.48322588],\n       [-1.56228098, -1.51781816, -1.41009931, ...,  1.36838693,\n        -0.85954108,  0.54589105],\n       [-1.58208984, -1.48135002, -1.42962127, ...,  1.29761393,\n        -1.09031956,  0.19035705]])"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN()\n",
    "#smote = SMOTE()\n",
    "\n",
    "# Fit SMOTE to the training data\n",
    "X_train_scaled, y_train = adasyn.fit_resample(X_train_scaled, y_train)\n",
    "X_train_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:23:34.162182900Z",
     "start_time": "2024-02-24T16:23:33.896794Z"
    }
   },
   "id": "15235663eb2ce3ed",
   "execution_count": 185
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Undersempling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5ea69bb25973531"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Instantiate RandomUnderSampler\n",
    "undersampler = RandomUnderSampler()\n",
    "\n",
    "# Fit undersampler to the training data\n",
    "X_train_scaled, y_train = undersampler.fit_resample(X_train_scaled, y_train)\n",
    "X_train_scaled"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b63f78ccb431a6f4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1939c22670fd8947"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "display(rfc.score(X_train_scaled, y_train))\n",
    "display(rfc.score(X_test_scaled, y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f16af680abab1b1c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "feats = {}\n",
    "for feature, importance in zip(data_for_analysis.drop(\"result\", axis=1).columns, rfc.feature_importances_):\n",
    "    feats[feature] = importance\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-Importance'})\n",
    "importances = importances.sort_values(by='Gini-Importance', ascending=False)\n",
    "importances = importances.reset_index()\n",
    "importances = importances.rename(columns={'index': 'Features'})\n",
    "sns.set(font_scale = 5)\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.7)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(30,15)\n",
    "sns.barplot(x=importances['Gini-Importance'], y=importances['Features'], data=importances, color='skyblue')\n",
    "plt.xlabel('Importance', fontsize=25, weight = 'bold')\n",
    "plt.ylabel('Features', fontsize=25, weight = 'bold')\n",
    "plt.title('Feature Importance', fontsize=25, weight = 'bold')\n",
    "display(plt.show())\n",
    "display(importances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad6d4a37b7ae9221",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_test = PCA(n_components=12)\n",
    "pca_test.fit(X_train_scaled)\n",
    "sns.set(style='whitegrid')\n",
    "plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.axvline(linewidth=4, color='r', linestyle = '--', x=10, ymin=0, ymax=1)\n",
    "display(plt.show())\n",
    "evr = pca_test.explained_variance_ratio_\n",
    "cvr = np.cumsum(pca_test.explained_variance_ratio_)\n",
    "pca_df = pd.DataFrame()\n",
    "pca_df['Cumulative Variance Ratio'] = cvr\n",
    "pca_df['Explained Variance Ratio'] = evr\n",
    "display(pca_df.head(10))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6006e656747be57d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "max_features = ['log2', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(start = 1, stop = 15, num = 15)]\n",
    "min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 50, num = 10)]\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 2, stop = 50, num = 10)]\n",
    "bootstrap = [True, False]\n",
    "param_dist = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "rs = RandomizedSearchCV(rfc, \n",
    "                        param_dist, \n",
    "                        n_iter = 100,\n",
    "                        cv = 3, \n",
    "                        verbose = 1, \n",
    "                        n_jobs=-1, \n",
    "                        random_state=0)\n",
    "rs.fit(X_train_scaled, y_train)\n",
    "rs.best_params_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c3ba2ef0c9903ef",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "just in case\n",
    "{'n_estimators': 800,\n",
    " 'min_samples_split': 28,\n",
    " 'min_samples_leaf': 12,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 14,\n",
    " 'bootstrap': True}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "\n",
    "# y_pred_probs = rfc.predict_proba(X_test_scaled)[:, 1]\n",
    "# \n",
    "# new_threshold = 0.8  # Example: setting a higher threshold\n",
    "# \n",
    "# # Adjust the predicted labels based on the new threshold\n",
    "# y_pred = (y_pred_probs >= new_threshold).astype(int)\n",
    "y_pred = rfc.predict(X_test_scaled)\n",
    "\n",
    "conf_matrix_baseline = pd.DataFrame(confusion_matrix(y_test, y_pred), index = ['actual 0', 'actual 1'], columns = ['predicted 0', 'predicted 1'])\n",
    "\n",
    "display(conf_matrix_baseline)\n",
    "display('Baseline Random Forest recall score', recall_score(y_test, y_pred))\n",
    "display('Baseline Random Forest precision score', precision_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25b364463886e796",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Create a Gradient Boosting Classifier instance\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "gbm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the training and test data\n",
    "train_score = gbm.score(X_train_scaled, y_train)\n",
    "test_score = gbm.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_score)\n",
    "print(\"Test Accuracy:\", test_score)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "542ac3bc419d44fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [12243, 88996]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[186], line 28\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Parameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, best_params)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Evaluate on test set\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m test_score \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest Accuracy:\u001B[39m\u001B[38;5;124m\"\u001B[39m, test_score)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:498\u001B[0m, in \u001B[0;36mBaseSearchCV.score\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    495\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scorer(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_estimator_, X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mscore_params)\n\u001B[0;32m    497\u001B[0m \u001B[38;5;66;03m# callable\u001B[39;00m\n\u001B[1;32m--> 498\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscorer_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_estimator_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mscore_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultimetric_:\n\u001B[0;32m    500\u001B[0m     score \u001B[38;5;241m=\u001B[39m score[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefit]\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:253\u001B[0m, in \u001B[0;36m_BaseScorer.__call__\u001B[1;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    251\u001B[0m     _kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msample_weight\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m sample_weight\n\u001B[1;32m--> 253\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_cached_call\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:350\u001B[0m, in \u001B[0;36m_Scorer._score\u001B[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001B[0m\n\u001B[0;32m    345\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m method_caller(\n\u001B[0;32m    346\u001B[0m     estimator, response_method\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, X, pos_label\u001B[38;5;241m=\u001B[39mpos_label\n\u001B[0;32m    347\u001B[0m )\n\u001B[0;32m    349\u001B[0m scoring_kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs}\n\u001B[1;32m--> 350\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sign \u001B[38;5;241m*\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_score_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mscoring_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2182\u001B[0m, in \u001B[0;36mprecision_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   2015\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m   2016\u001B[0m     {\n\u001B[0;32m   2017\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2042\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2043\u001B[0m ):\n\u001B[0;32m   2044\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[0;32m   2045\u001B[0m \n\u001B[0;32m   2046\u001B[0m \u001B[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2180\u001B[0m \u001B[38;5;124;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[0;32m   2181\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2182\u001B[0m     p, _, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2183\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2184\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2187\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2189\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2191\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[1;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1767\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1604\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[0;32m   1605\u001B[0m \n\u001B[0;32m   1606\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1764\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1766\u001B[0m _check_zero_division(zero_division)\n\u001B[1;32m-> 1767\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1769\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[0;32m   1770\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1539\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m average_options \u001B[38;5;129;01mand\u001B[39;00m average \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1537\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage has to be one of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(average_options))\n\u001B[1;32m-> 1539\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1540\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[0;32m   1541\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[0;32m   1542\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_targets\u001B[39m(y_true, y_pred):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \n\u001B[0;32m     61\u001B[0m \u001B[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;124;03m    y_pred : array or indicator matrix\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m     \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m     type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     87\u001B[0m     type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MarketBot\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    455\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 457\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    458\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    459\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    460\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [12243, 88996]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Instantiate the GBM classifier\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "scorer = make_scorer(precision_score)\n",
    "\n",
    "# Instantiate GridSearchCV with precision as the scoring metric\n",
    "grid_search = GridSearchCV(gbm, param_grid, cv=5, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_score = grid_search.score(X_train_scaled, y_test)\n",
    "print(\"Test Accuracy:\", test_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:54:54.801917900Z",
     "start_time": "2024-02-24T16:23:50.918742100Z"
    }
   },
   "id": "ba39d8cdf7cc65b2",
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200}\n",
      "Test Accuracy: 0.15275634731378876\n"
     ]
    },
    {
     "data": {
      "text/plain": "          predicted 0  predicted 1\nactual 0         7439         3671\nactual 1          161          972",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predicted 0</th>\n      <th>predicted 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>actual 0</th>\n      <td>7439</td>\n      <td>3671</td>\n    </tr>\n    <tr>\n      <th>actual 1</th>\n      <td>161</td>\n      <td>972</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall Score: 0.9611650485436893\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Test precision score'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.15275634731378876"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_score = grid_search.score(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "\n",
    "y_pred_test = grid_search.predict(X_test_scaled)\n",
    "\n",
    "display(conf_matrix_baseline)\n",
    "print(\"Test Recall Score:\", recall_score(y_test, y_pred_test))\n",
    "display('Test precision score', precision_score(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T17:09:53.409231900Z",
     "start_time": "2024-02-24T17:09:53.294227900Z"
    }
   },
   "id": "391e44eaa02b6ab2",
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate recall score on the test data\n",
    "y_pred_test = gbm.predict(X_test_scaled)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "\n",
    "conf_matrix_baseline = pd.DataFrame(confusion_matrix(y_test, y_pred_test), index = ['actual 0', 'actual 1'], columns = ['predicted 0', 'predicted 1'])\n",
    "\n",
    "display(conf_matrix_baseline)\n",
    "print(\"Test Recall Score:\", recall)\n",
    "display('Test precision score', precision_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba9488e0fb6cb709",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
